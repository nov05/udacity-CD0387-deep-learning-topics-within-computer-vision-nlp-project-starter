{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f909c62",
   "metadata": {},
   "source": [
    "## Exercise: Build a Neural Network\n",
    "\n",
    "For this exercise, your task is to write code to build a neural network. The choice for the number of layers, and the number of neurons is up to you. However, since we will be using the MNIST dataset in this example, you will need to have 784 neurons in your input layer and 10 neurons in your output layer. Here are the steps you need to do:\n",
    "\n",
    "1. Create your model in the `create_model()` function.\n",
    "2. Return the model you created at the end of the function.\n",
    "\n",
    "**Note**: It may take 5 - 10 minutes to download the data sets. \n",
    "\n",
    "In case you get stuck, you can look at the solution notebook.\n",
    "\n",
    "### Try It Out!\n",
    "- Change the number of layers and neurons in your model. How does your model accuracy change? These values are called hyperparameters and they can change the performance of our model. In a later lesson, we will learn how to automatically search for hyperparameters that give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b50071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def create_model():\n",
    "    #TODO: Build and return a feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from main import create_model\n",
    "\n",
    "def train(model, train_loader, cost, optimizer, epoch):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        running_loss=0\n",
    "        correct=0\n",
    "        for data, target in train_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = cost(pred, target)\n",
    "            running_loss+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred=pred.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, Accuracy {100*(correct/len(train_loader.dataset))}%\")\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} = {100*(correct/len(test_loader.dataset))}%)')\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Set Hyperparameters\n",
    "batch_size=64\n",
    "epoch=10\n",
    "\n",
    "print(\"Downloading Data\")\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('data/', download=True, train=True, transform=training_transform)\n",
    "testset = datasets.MNIST('data/', download=True, train=False, transform=testing_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Loading Model\")\n",
    "model=create_model()\n",
    "\n",
    "cost = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"Starting Model Training\")\n",
    "train(model, train_loader, cost, optimizer, epoch)\n",
    "print(\"Testing Trained Model\")\n",
    "test(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
