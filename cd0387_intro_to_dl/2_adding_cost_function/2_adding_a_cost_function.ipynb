{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d84d95",
   "metadata": {},
   "source": [
    "## Adding Cost Function and Optimization to Neural Networks\n",
    "\n",
    "For this exercise, your task is to add a Cost Function and Optimizer to the neural network you built in the last exercise. You will need to figure out what is the correct cost function and optimizer to use for your neural network architecture. Here are the steps you need to do:\n",
    "\n",
    "1. Complete the `create_model()` function. You can either create a new network or use the network you built in the previous exercise\n",
    "2. Add your cost function and optimizer\n",
    "\n",
    "**Note**: It may take 5 - 10 minutes to download the data sets. \n",
    "\n",
    "In case you get stuck, you can look at the solution below.\n",
    "\n",
    "### Try It Out!\n",
    "- Change the parameters of your optimizer and for your network. How does your model accuracy change? These values are called hyperparameters and they can change the performance of our model. In a later lesson, we will learn how to automatically search for hyperparameters that give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from main import model, cost, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #TODO: Build a feed-forward network.\n",
    "    # You can use the network you built in previous exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae169175",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "cost = #TODO: Add your cost function here\n",
    "optimizer = #TODO: Add your optimizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90284a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, cost, optimizer, epoch):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        running_loss=0\n",
    "        correct=0\n",
    "        for data, target in train_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = cost(pred, target)\n",
    "            running_loss+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred=pred.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, Accuracy {100*(correct/len(train_loader.dataset))}%\")\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} = {100*(correct/len(test_loader.dataset))}%)')\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Set Hyperparameters\n",
    "batch_size=64\n",
    "epoch=10\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('data/', download=True, train=True, transform=training_transform)\n",
    "testset = datasets.MNIST('data/', download=True, train=False, transform=testing_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train(model, train_loader, cost, optimizer, epoch)\n",
    "test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
