warning: in the working copy of 'cd0387_common_model_arch_types_fine_tuning/training_a_cnn_solution.ipynb', LF will be replaced by CRLF the next time Git touches it
diff --git a/cd0387_common_model_arch_types_fine_tuning/training_a_cnn_solution.ipynb b/cd0387_common_model_arch_types_fine_tuning/training_a_cnn_solution.ipynb
index ef0600e..29a94cd 100644
--- a/cd0387_common_model_arch_types_fine_tuning/training_a_cnn_solution.ipynb
+++ b/cd0387_common_model_arch_types_fine_tuning/training_a_cnn_solution.ipynb
@@ -58,7 +58,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 11,
    "id": "53abdfd8",
    "metadata": {},
    "outputs": [],
@@ -71,12 +71,33 @@
     "from torchvision.models import resnet18, ResNet18_Weights\n",
     "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
     "import time\n",
-    "from tqdm import tqdm"
+    "from tqdm import tqdm\n",
+    "import wandb\n",
+    "\n",
+    "## log training process with W&B if uncommented\n",
+    "# os.environ['WANDB_MODE'] = 'disabled'"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 15,
+   "id": "ac2effae",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "class Config:\n",
+    "    DEVICE = torch.device('cpu')\n",
+    "    def __init__(self):\n",
+    "        self.wandb = True\n",
+    "        self.epochs = 30\n",
+    "        self.batch_size = 256\n",
+    "        self.opt_lr = 2e-4\n",
+    "        self.opt_weight_decay = 1e-4"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
    "id": "3258e068",
    "metadata": {},
    "outputs": [
@@ -84,297 +105,38 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "👉 Running on Device cuda:0\n",
+      "👉 Running on device type: cuda:0\n",
       "Files already downloaded and verified\n",
       "Files already downloaded and verified\n"
      ]
     },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  0%|          | 0/100 [00:00<?, ?it/s]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Epoch 0, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.81 Accuracy: 9755/16000 (60.97%) Time: Thu Nov 28 17:09:15 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.87 Accuracy: 21742/32000 (67.94%) Time: Thu Nov 28 17:09:59 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.60 Accuracy: 34069/48000 (70.98%) Time: Thu Nov 28 17:11:18 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.61 Accuracy: 35639/50000 (71.28%) Time: Thu Nov 28 17:11:31 2024\n",
-      "Epoch 0, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  1%|          | 1/100 [03:51<6:22:32, 231.84s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.69 Accuracy: 7846/10000 (78.46%) Time: Thu Nov 28 17:12:23 2024\n",
-      "Epoch 1, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.65 Accuracy: 12512/16000 (78.20%) Time: Thu Nov 28 17:13:32 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.76 Accuracy: 25172/32000 (78.66%) Time: Thu Nov 28 17:14:44 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.49 Accuracy: 37889/48000 (78.94%) Time: Thu Nov 28 17:15:55 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.58 Accuracy: 39499/50000 (79.00%) Time: Thu Nov 28 17:16:05 2024\n",
-      "Epoch 1, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  2%|▏         | 2/100 [08:17<6:51:05, 251.69s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.60 Accuracy: 7993/10000 (79.93%) Time: Thu Nov 28 17:16:49 2024\n",
-      "Epoch 2, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.49 Accuracy: 12821/16000 (80.13%) Time: Thu Nov 28 17:17:58 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.57 Accuracy: 25645/32000 (80.14%) Time: Thu Nov 28 17:19:09 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.55 Accuracy: 38482/48000 (80.17%) Time: Thu Nov 28 17:20:29 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.58 Accuracy: 40115/50000 (80.23%) Time: Thu Nov 28 17:20:39 2024\n",
-      "Epoch 2, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  3%|▎         | 3/100 [12:54<7:05:53, 263.44s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.53 Accuracy: 7981/10000 (79.81%) Time: Thu Nov 28 17:21:26 2024\n",
-      "Epoch 3, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.66 Accuracy: 12817/16000 (80.11%) Time: Thu Nov 28 17:22:42 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.52 Accuracy: 25656/32000 (80.17%) Time: Thu Nov 28 17:24:01 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.52 Accuracy: 38521/48000 (80.25%) Time: Thu Nov 28 17:25:26 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.58 Accuracy: 40143/50000 (80.29%) Time: Thu Nov 28 17:25:36 2024\n",
-      "Epoch 3, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  4%|▍         | 4/100 [17:53<7:23:50, 277.40s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.52 Accuracy: 8051/10000 (80.51%) Time: Thu Nov 28 17:26:25 2024\n",
-      "Epoch 4, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.45 Accuracy: 12931/16000 (80.82%) Time: Thu Nov 28 17:27:37 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.52 Accuracy: 25816/32000 (80.67%) Time: Thu Nov 28 17:28:56 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.58 Accuracy: 38815/48000 (80.86%) Time: Thu Nov 28 17:30:11 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.41 Accuracy: 40386/50000 (80.77%) Time: Thu Nov 28 17:30:21 2024\n",
-      "Epoch 4, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  5%|▌         | 5/100 [22:40<7:24:50, 280.96s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.47 Accuracy: 8072/10000 (80.72%) Time: Thu Nov 28 17:31:12 2024\n",
-      "Epoch 5, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.58 Accuracy: 12940/16000 (80.88%) Time: Thu Nov 28 17:32:26 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.57 Accuracy: 25860/32000 (80.81%) Time: Thu Nov 28 17:33:36 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.45 Accuracy: 38796/48000 (80.83%) Time: Thu Nov 28 17:34:48 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.57 Accuracy: 40423/50000 (80.85%) Time: Thu Nov 28 17:34:57 2024\n",
-      "Epoch 5, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  6%|▌         | 6/100 [27:05<7:11:27, 275.40s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.48 Accuracy: 8102/10000 (81.02%) Time: Thu Nov 28 17:35:37 2024\n",
-      "Epoch 6, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.42 Accuracy: 12898/16000 (80.61%) Time: Thu Nov 28 17:36:46 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.43 Accuracy: 25912/32000 (80.97%) Time: Thu Nov 28 17:37:52 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.46 Accuracy: 38882/48000 (81.00%) Time: Thu Nov 28 17:38:59 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.67 Accuracy: 40512/50000 (81.02%) Time: Thu Nov 28 17:39:07 2024\n",
-      "Epoch 6, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  7%|▋         | 7/100 [31:14<6:53:24, 266.71s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.52 Accuracy: 8024/10000 (80.24%) Time: Thu Nov 28 17:39:46 2024\n",
-      "Epoch 7, Phase train\n",
-      "Images [16000/50000 (32%)] Loss: 0.55 Accuracy: 12997/16000 (81.23%) Time: Thu Nov 28 17:40:50 2024\n",
-      "Images [32000/50000 (64%)] Loss: 0.53 Accuracy: 26036/32000 (81.36%) Time: Thu Nov 28 17:41:54 2024\n",
-      "Images [48000/50000 (96%)] Loss: 0.44 Accuracy: 38964/48000 (81.17%) Time: Thu Nov 28 17:43:00 2024\n",
-      "Images [50000/50000 (100%)] Loss: 0.70 Accuracy: 40586/50000 (81.17%) Time: Thu Nov 28 17:43:07 2024\n",
-      "Epoch 7, Phase eval\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "  7%|▋         | 7/100 [35:15<7:48:22, 302.18s/it]"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Images [10000/10000 (100%)] Loss: 0.48 Accuracy: 8086/10000 (80.86%) Time: Thu Nov 28 17:43:47 2024\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\n"
-     ]
-    },
     {
      "data": {
+      "text/html": [
+       "Finishing last run (ID:fgmdjaop) before initializing another..."
+      ],
       "text/plain": [
-       "ResNet(\n",
-       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
-       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "  (relu): ReLU(inplace=True)\n",
-       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
-       "  (layer1): Sequential(\n",
-       "    (0): BasicBlock(\n",
-       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "    )\n",
-       "    (1): BasicBlock(\n",
-       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "    )\n",
-       "  )\n",
-       "  (layer2): Sequential(\n",
-       "    (0): BasicBlock(\n",
-       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (downsample): Sequential(\n",
-       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
-       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      )\n",
-       "    )\n",
-       "    (1): BasicBlock(\n",
-       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "    )\n",
-       "  )\n",
-       "  (layer3): Sequential(\n",
-       "    (0): BasicBlock(\n",
-       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (downsample): Sequential(\n",
-       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
-       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      )\n",
-       "    )\n",
-       "    (1): BasicBlock(\n",
-       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "    )\n",
-       "  )\n",
-       "  (layer4): Sequential(\n",
-       "    (0): BasicBlock(\n",
-       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (downsample): Sequential(\n",
-       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
-       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      )\n",
-       "    )\n",
-       "    (1): BasicBlock(\n",
-       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "      (relu): ReLU(inplace=True)\n",
-       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
-       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
-       "    )\n",
-       "  )\n",
-       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
-       "  (fc): Sequential(\n",
-       "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
-       "  )\n",
-       ")"
+       "<IPython.core.display.HTML object>"
       ]
      },
-     "execution_count": 8,
      "metadata": {},
-     "output_type": "execute_result"
+     "output_type": "display_data"
     }
    ],
    "source": [
-    "def test(model, test_loader, criterion, device):\n",
+    "config = Config()\n",
+    "config.DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
+    "print(f\"👉 Running on device type: {config.DEVICE}\")\n",
+    "\n",
+    "def test(model, test_loader, criterion):\n",
     "    print(\"Testing model on whole testing dataset...\")\n",
     "    model.eval()\n",
     "    running_loss=0\n",
     "    running_corrects=0\n",
     "    \n",
     "    for inputs, labels in test_loader:\n",
-    "        inputs=inputs.to(device)\n",
-    "        labels=labels.to(device)\n",
+    "        inputs=inputs.to(config.DEVICE)\n",
+    "        labels=labels.to(config.DEVICE)\n",
     "        outputs=model(inputs)\n",
     "        loss=criterion(outputs, labels)\n",
     "        _, preds = torch.max(outputs, 1)\n",
@@ -386,14 +148,14 @@
     "    print(f\"🟢 Testing Accuracy: {100*total_acc}, Testing Loss: {total_loss}\")\n",
     "    \n",
     "\n",
-    "def train(model, train_loader, validation_loader, criterion, optimizer, device,\n",
-    "          epochs):\n",
+    "def train(model, train_loader, validation_loader, criterion, optimizer):\n",
     "\n",
-    "    best_loss=1e6\n",
-    "    image_dataset={'train':train_loader, 'eval':validation_loader}\n",
-    "    loss_counter=0\n",
+    "    best_loss = 1e6\n",
+    "    image_dataset = {'train':train_loader, 'eval':validation_loader}\n",
+    "    epoch_loss_counter = 0\n",
+    "    total_steps = 0\n",
     "    \n",
-    "    for epoch in tqdm(range(epochs)):\n",
+    "    for epoch in tqdm(range(config.epochs)):\n",
     "        for phase in ['train', 'eval']:\n",
     "            print(f\"Epoch {epoch}, Phase {phase}\")\n",
     "            if phase=='train':\n",
@@ -405,10 +167,12 @@
     "            running_samples=0\n",
     "\n",
     "            for step, (inputs, labels) in enumerate(image_dataset[phase]):\n",
-    "                inputs=inputs.to(device)\n",
-    "                labels=labels.to(device)\n",
+    "                total_steps += 1\n",
+    "                inputs=inputs.to(config.DEVICE)\n",
+    "                labels=labels.to(config.DEVICE)\n",
     "                outputs = model(inputs)\n",
     "                loss = criterion(outputs, labels)\n",
+    "                wandb.log({\"loss\": loss}, step=total_steps)\n",
     "\n",
     "                if phase=='train':\n",
     "                    optimizer.zero_grad()\n",
@@ -420,50 +184,45 @@
     "                running_corrects += torch.sum(preds==labels.data).item()\n",
     "                running_samples += len(inputs)\n",
     "                if (running_samples%2000)==0:\n",
-    "                    accuracy = running_corrects/running_samples\n",
-    "                    print(\"Step {}, Images [{}/{} ({:.0f}%)] Loss: {:.2f} Accuracy: {}/{} ({:.2f}%) Time: {}\".format(\n",
-    "                            step,\n",
-    "                            running_samples,\n",
-    "                            len(image_dataset[phase].dataset),\n",
-    "                            100.0 * (running_samples / len(image_dataset[phase].dataset)),\n",
-    "                            loss.item(),\n",
-    "                            running_corrects,\n",
-    "                            running_samples,\n",
-    "                            100.0*accuracy,\n",
-    "                            time.asctime() # for measuring time for testing, remove for students and in the formatting\n",
-    "                        )\n",
-    "                    )\n",
+    "                    accuracy = running_corrects / running_samples\n",
+    "                    wandb.log({\"accuracy (%)\": accuracy}, step=total_steps)\n",
+    "                    print(f\"Step {step}, Images [{running_samples}/{len(image_dataset[phase].dataset)} \"\n",
+    "                          f\"({100.0 * (running_samples / len(image_dataset[phase].dataset)):.0f}%)] \"\n",
+    "                          f\"Loss: {loss.item():.2f} Accuracy: {running_corrects}/{running_samples} \"\n",
+    "                          ## for measuring time for testing, remove for students and in the formatting\n",
+    "                          f\"({accuracy*100.:.2f}%) Time: {time.asctime()}\")\n",
+    "        \n",
     "                ## NOTE: Comment lines below to train and test on whole dataset\n",
     "                # if running_samples>(0.2*len(image_dataset[phase].dataset)):\n",
     "                #     break\n",
     "\n",
     "            epoch_loss = running_loss / running_samples\n",
-    "            # epoch_acc = running_corrects / running_samples\n",
+    "            wandb.log({\"epoch_loss\": epoch_loss}, step=total_steps)\n",
+    "            epoch_accuracy = running_corrects / running_samples\n",
+    "            wandb.log({\"epoch_accuracy (%)\": epoch_accuracy}, step=total_steps)\n",
     "            \n",
     "            if phase=='eval':\n",
     "                if epoch_loss<best_loss:\n",
     "                    best_loss=epoch_loss\n",
+    "                    epoch_loss_counter = 0  ## reset \n",
     "                else:\n",
     "                    loss_counter+=1\n",
-    "        ## early stopping\n",
-    "        if loss_counter==2:\n",
+    "        ## early stop if epoch_loss stop decreasing\n",
+    "        if epoch_loss_counter==3:\n",
     "            break\n",
     "    return model\n",
     "\n",
     "def create_model():\n",
-    "    # model = resnet18(pretrained=True)\n",
+    "    # model = resnet18(pretrained=True)  ## future warning: obsolete\n",
     "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
     "    for param in model.parameters():\n",
-    "        param.requires_grad = False   \n",
+    "        param.requires_grad = False  ## freeze resnet18  \n",
     "    num_features=model.fc.in_features\n",
     "    model.fc = nn.Sequential(\n",
     "        nn.Linear(num_features, 10)\n",
     "    )\n",
     "    return model\n",
     "\n",
-    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
-    "print(f\"👉 Running on Device {device}\")\n",
-    "\n",
     "training_transform = transforms.Compose([\n",
     "    transforms.RandomHorizontalFlip(p=0.5),\n",
     "    transforms.Resize(224),\n",
@@ -475,27 +234,39 @@
     "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
     "\n",
     "\n",
-    "epochs=100\n",
-    "batch_size=128\n",
+    "########################################################################\n",
+    "## create model\n",
+    "########################################################################\n",
     "model=create_model()\n",
-    "model=model.to(device)\n",
+    "model=model.to(config.DEVICE)\n",
     "criterion = nn.CrossEntropyLoss()\n",
-    "optimizer = optim.AdamW(model.fc.parameters(), lr=0.001, weight_decay=5e-4)\n",
+    "optimizer = optim.AdamW(model.fc.parameters(), lr=config.opt_lr, weight_decay=config.opt_weight_decay)\n",
     "# optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
-    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
+    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
     "\n",
     "trainset = CIFAR10(root='./data', train=True,\n",
     "    download=True, transform=training_transform)\n",
-    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
+    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size,\n",
     "    shuffle=True)\n",
     "testset = CIFAR10(root='./data', train=False,\n",
     "    download=True, transform=testing_transform)\n",
-    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
+    "testloader = torch.utils.data.DataLoader(testset, batch_size=config.batch_size,\n",
     "    shuffle=False)\n",
     "\n",
-    "train(model, trainloader, testloader, criterion, optimizer, device, epochs)\n",
+    "config.wandb = True\n",
+    "wandb.init(\n",
+    "    # set the wandb project where this run will be logged\n",
+    "    project=\"udacity-awsmle-resnet18-cifar10\",\n",
+    "    config=config\n",
+    ")\n",
+    "\n",
+    "########################################################################\n",
+    "## training\n",
+    "########################################################################\n",
+    "train(model, trainloader, testloader, criterion, optimizer)\n",
     "## Epoch 0, Phase train\n",
-    "## Images [2000/50000 (4%)] Loss: 1.16 Accuracy: 846/2000 (42.30%) Time: Thu Nov 28 16:48:06 2024"
+    "## Images [2000/50000 (4%)] Loss: 1.16 Accuracy: 846/2000 (42.30%) Time: Thu Nov 28 16:48:06 2024\n",
+    "## "
    ]
   },
   {
@@ -503,18 +274,9 @@
    "execution_count": null,
    "id": "c2e175f9",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Testing model on whole testing dataset...\n",
-      "🟢 Testing Accuracy: 80.86, Testing Loss: 0.5680697995185852\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
-    "test(model, testloader, criterion, device)\n",
+    "test(model, testloader, criterion)\n",
     "## Testing Accuracy: 80.86, Testing Loss: 0.5680697995185852\n",
     "## 24.5s"
    ]
