{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63d6c50",
   "metadata": {},
   "source": [
    "* changed by nov05 on 2024-11-28  \n",
    "* Udacity AWS MLE Nanodegree (ND189)  \n",
    "  Course 4, 3.7 Exercise: Training a Convolutional Neural Network  \n",
    "* `conda activate drlnd_py310` with cuda enabled   \n",
    "* Training:  \n",
    "  * freeze all the layers of resnet18, check [the W&B logs](https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/28gkg0jn)    \n",
    "    Testing Accuracy: 80.86, Testing Loss: 0.5680697995185852   \n",
    "  * freeze most of the layers from the bottom of resnet18, check [the W&B logs](https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/ouiinmmp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\github\\udacity-CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\guido\\miniconda3\\envs\\drlnd_py310\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d:\\\\github\\\\udacity-CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use the repo root folder as working directory\n",
    "## training data is in data\\\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed8603",
   "metadata": {},
   "source": [
    "## Solution: Training a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53abdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "## log training process with W&B if uncommented\n",
    "# os.environ['WANDB_MODE'] = 'disabled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2effae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    def __init__(self):\n",
    "        self.wandb = True\n",
    "        self.epochs = 30\n",
    "        self.batch_size = 256\n",
    "        self.opt_lr = 1e-4\n",
    "        self.opt_weight_decay = 1e-4\n",
    "        self.unfreeze_top_layers = True\n",
    "\n",
    "config = Config()\n",
    "config.DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üëâ Running on device type: {config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Running on device type: cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ouiinmmp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy (%)</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÖ</td></tr><tr><td>epoch_accuracy_eval (%)</td><td>‚ñÅ‚ñà‚ñá</td></tr><tr><td>epoch_accuracy_train (%)</td><td>‚ñÅ‚ñÜ‚ñà</td></tr><tr><td>epoch_loss_eval</td><td>‚ñà‚ñÅ‚ñà</td></tr><tr><td>epoch_loss_train</td><td>‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy (%)</td><td>0.9069</td></tr><tr><td>epoch_accuracy_eval (%)</td><td>0.9069</td></tr><tr><td>epoch_accuracy_train (%)</td><td>0.96734</td></tr><tr><td>epoch_loss_eval</td><td>0.301</td></tr><tr><td>epoch_loss_train</td><td>0.10426</td></tr><tr><td>loss</td><td>0.04952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-star-4</strong> at: <a href='https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/ouiinmmp' target=\"_blank\">https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/ouiinmmp</a><br/> View project at: <a href='https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10' target=\"_blank\">https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241128_205038-ouiinmmp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ouiinmmp). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\github\\udacity-CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter\\wandb\\run-20241128_211031-piinbhsu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/piinbhsu' target=\"_blank\">eager-wood-5</a></strong> to <a href='https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10' target=\"_blank\">https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/piinbhsu' target=\"_blank\">https://wandb.ai/nov05/udacity-awsmle-resnet18-cifar10/runs/piinbhsu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Epoch 0, Phase \"train\"\n",
      "Step 125, Images [32000/50000 (64%)] Loss: 0.33 Accuracy: 25544/32000 (79.83%) Time: Thu Nov 28 21:13:11 2024\n",
      "Step 196, Images [50000/50000 (100%)] Loss: 0.37 Accuracy: 41515/50000 (83.03%) Time: Thu Nov 28 21:14:58 2024\n",
      "üëâ Epoch 0, Phase \"eval\"\n",
      "Step 236, Images [10000/10000 (100%)] Loss: 0.11 Accuracy: 8910/10000 (89.10%) Time: Thu Nov 28 21:15:44 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 1/30 [05:09<2:29:40, 309.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Epoch 1, Phase \"train\"\n",
      "Step 361, Images [32000/50000 (64%)] Loss: 0.21 Accuracy: 29660/32000 (92.69%) Time: Thu Nov 28 21:18:53 2024\n",
      "Step 432, Images [50000/50000 (100%)] Loss: 0.19 Accuracy: 46292/50000 (92.58%) Time: Thu Nov 28 21:20:30 2024\n",
      "üëâ Epoch 1, Phase \"eval\"\n",
      "Step 472, Images [10000/10000 (100%)] Loss: 0.09 Accuracy: 9040/10000 (90.40%) Time: Thu Nov 28 21:21:25 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 2/30 [10:51<2:33:14, 328.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Epoch 2, Phase \"train\"\n",
      "Step 597, Images [32000/50000 (64%)] Loss: 0.13 Accuracy: 30649/32000 (95.78%) Time: Thu Nov 28 21:24:33 2024\n",
      "Step 668, Images [50000/50000 (100%)] Loss: 0.28 Accuracy: 47833/50000 (95.67%) Time: Thu Nov 28 21:26:12 2024\n",
      "üëâ Epoch 2, Phase \"eval\"\n",
      "Step 708, Images [10000/10000 (100%)] Loss: 0.09 Accuracy: 9090/10000 (90.90%) Time: Thu Nov 28 21:27:00 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 3/30 [16:25<2:28:56, 330.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Epoch 3, Phase \"train\"\n",
      "Step 833, Images [32000/50000 (64%)] Loss: 0.07 Accuracy: 31212/32000 (97.54%) Time: Thu Nov 28 21:29:54 2024\n",
      "Step 904, Images [50000/50000 (100%)] Loss: 0.11 Accuracy: 48804/50000 (97.61%) Time: Thu Nov 28 21:31:29 2024\n",
      "üëâ Epoch 3, Phase \"eval\"\n",
      "Step 944, Images [10000/10000 (100%)] Loss: 0.04 Accuracy: 9115/10000 (91.15%) Time: Thu Nov 28 21:32:17 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 4/30 [21:43<2:21:10, 325.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Epoch 4, Phase \"train\"\n",
      "Step 1069, Images [32000/50000 (64%)] Loss: 0.05 Accuracy: 31600/32000 (98.75%) Time: Thu Nov 28 21:35:20 2024\n",
      "Step 1140, Images [50000/50000 (100%)] Loss: 0.05 Accuracy: 49341/50000 (98.68%) Time: Thu Nov 28 21:37:06 2024\n",
      "üëâ Epoch 4, Phase \"eval\"\n",
      "Step 1180, Images [10000/10000 (100%)] Loss: 0.06 Accuracy: 9124/10000 (91.24%) Time: Thu Nov 28 21:37:50 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 5/30 [27:16<2:16:49, 328.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Epoch 5, Phase \"train\"\n",
      "Step 1305, Images [32000/50000 (64%)] Loss: 0.01 Accuracy: 31801/32000 (99.38%) Time: Thu Nov 28 21:40:40 2024\n",
      "Step 1376, Images [50000/50000 (100%)] Loss: 0.05 Accuracy: 49672/50000 (99.34%) Time: Thu Nov 28 21:42:15 2024\n",
      "üëâ Epoch 5, Phase \"eval\"\n",
      "Step 1416, Images [10000/10000 (100%)] Loss: 0.03 Accuracy: 9155/10000 (91.55%) Time: Thu Nov 28 21:42:58 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 5/30 [32:23<2:41:57, 388.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    print(\"Testing model on whole testing dataset...\")\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    running_corrects=0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs=inputs.to(config.DEVICE)\n",
    "        labels=labels.to(config.DEVICE)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds==labels.data).item()\n",
    "\n",
    "    total_loss = running_loss / len(test_loader.dataset)\n",
    "    total_acc = running_corrects/ len(test_loader.dataset)\n",
    "    print(f\"üü¢ Testing Accuracy: {100*total_acc}, Testing Loss: {total_loss}\")\n",
    "    \n",
    "\n",
    "def train(model, train_loader, validation_loader, criterion, optimizer):\n",
    "\n",
    "    best_loss = 1e6\n",
    "    image_dataset = {'train':train_loader, 'eval':validation_loader}\n",
    "    epoch_loss_counter = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for phase in ['train', 'eval']:\n",
    "            print(f\"üëâ Epoch {epoch}, Phase \\\"{phase}\\\"\")\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_samples=0\n",
    "\n",
    "            for _, (inputs, labels) in enumerate(image_dataset[phase]):\n",
    "                total_steps += 1\n",
    "                inputs=inputs.to(config.DEVICE)\n",
    "                labels=labels.to(config.DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                wandb.log({\"loss\": loss}, step=total_steps)\n",
    "\n",
    "                if phase=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds==labels.data).item()\n",
    "                running_samples += len(inputs)\n",
    "                if (running_samples%2000)==0:\n",
    "                    accuracy = running_corrects / running_samples\n",
    "                    wandb.log({\"accuracy (%)\": accuracy}, step=total_steps)\n",
    "                    print(f\"Step {total_steps}, Images [{running_samples}/{len(image_dataset[phase].dataset)} \"\n",
    "                          f\"({100.0 * (running_samples / len(image_dataset[phase].dataset)):.0f}%)] \"\n",
    "                          f\"Loss: {loss.item():.2f} Accuracy: {running_corrects}/{running_samples} \"\n",
    "                          ## for measuring time for testing, remove for students and in the formatting\n",
    "                          f\"({accuracy*100.:.2f}%) Time: {time.asctime()}\")\n",
    "\n",
    "                ## NOTE: Comment lines below to train and test on whole dataset\n",
    "                # if running_samples>(0.2*len(image_dataset[phase].dataset)):\n",
    "                #     break\n",
    "\n",
    "            epoch_loss = running_loss / running_samples\n",
    "            wandb.log({f\"epoch_loss_{phase}\": epoch_loss}, step=total_steps)\n",
    "            epoch_accuracy = running_corrects / running_samples\n",
    "            wandb.log({f\"epoch_accuracy_{phase} (%)\": epoch_accuracy}, step=total_steps)\n",
    "            \n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "            else:  ## eval\n",
    "                if epoch_loss<best_loss:\n",
    "                    best_loss=epoch_loss\n",
    "                    epoch_loss_counter = 0  ## reset \n",
    "                else:\n",
    "                    epoch_loss_counter += 1\n",
    "        ## early stop if epoch_loss stops decreasing\n",
    "        if epoch_loss_counter==2:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    # model = resnet18(pretrained=True)  ## future warning: obsolete\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False  ## freeze resnet18  \n",
    "    if config.unfreeze_top_layers==True:\n",
    "        # Unfreeze the last residual block (layer4)\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 10)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "########################################################################\n",
    "## create model\n",
    "########################################################################\n",
    "model=create_model()\n",
    "model=model.to(config.DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()  ## CIFAR10 has 10 classes\n",
    "if config.unfreeze_top_layers==True:\n",
    "    # Use an optimizer that only updates unfrozen layers\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=config.opt_lr, weight_decay=config.opt_weight_decay)\n",
    "else:\n",
    "    optimizer = optim.AdamW(model.fc.parameters(), lr=config.opt_lr, weight_decay=config.opt_weight_decay)\n",
    "    # optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "    download=True, transform=training_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size,\n",
    "    shuffle=True)\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "    download=True, transform=testing_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=config.batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"udacity-awsmle-resnet18-cifar10\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "########################################################################\n",
    "## training\n",
    "########################################################################\n",
    "train(model, trainloader, testloader, criterion, optimizer)\n",
    "\n",
    "## freezed all layers of resnet18: \n",
    "##     Epoch 0, Phase train\n",
    "##     Images [2000/50000 (4%)] Loss: 1.16 Accuracy: 846/2000 (42.30%) Time: Thu Nov 28 16:48:06 2024\n",
    "##     Epoch 20, Phase eval\n",
    "##     Step 39, Images [10000/10000 (100%)] Loss: 0.52 Accuracy: 8073/10000 (80.73%) Time: Thu Nov 28 20:46:01 2024\n",
    "##     20 epochs, 101m 35.8s\n",
    "## unfreeze layer4 of resnet18:\n",
    "##     üëâ Epoch 5, Phase \"eval\"\n",
    "##     Step 1416, Images [10000/10000 (100%)] Loss: 0.03 Accuracy: 9155/10000 (91.55%) Time: Thu Nov 28 21:42:58 2024 \n",
    "##     32m    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e175f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on whole testing dataset...\n",
      "üü¢ Testing Accuracy: 91.55, Testing Loss: 0.27510506587028505\n"
     ]
    }
   ],
   "source": [
    "test(model, testloader, criterion)\n",
    "## Freeze all Resnet18 layers, Testing Accuracy: 80.86, Testing Loss: 0.5680697995185852\n",
    "## Unfreeze layer4 of Resnet18, Testing Accuracy: 91.55, Testing Loss: 0.27510506587028505\n",
    "## 24.5s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98582f",
   "metadata": {},
   "source": [
    "```python\n",
    "ResNet(\n",
    "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (relu): ReLU(inplace=True)\n",
    "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "  (layer1): Sequential(\n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    (1): BasicBlock(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer2): Sequential(\n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (downsample): Sequential(\n",
    "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "    (1): BasicBlock(\n",
    "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer3): Sequential(\n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (downsample): Sequential(\n",
    "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "    (1): BasicBlock(\n",
    "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (layer4): Sequential(\n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (downsample): Sequential(\n",
    "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "    (1): BasicBlock(\n",
    "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (fc): Sequential(\n",
    "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
    "  )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec760cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
